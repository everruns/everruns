// Core traits for pluggable backends
//
// These traits allow the agent loop to be used with different backends:
// - In-memory implementations for examples and testing
// - Database implementations for production
// - gRPC-backed implementations for worker processes

use async_trait::async_trait;
use std::sync::Arc;
use uuid::Uuid;

use everruns_schemas::{
    Agent, ContentPart, Controls, Event, FileInfo, FileStat, GrepMatch, LlmProviderType, Message,
    MessageRole, Session, SessionFile, ToolCall, ToolDefinition, ToolResult,
};

use crate::error::Result;

// ============================================================================
// MessageStore - For persisting conversation messages
// ============================================================================

/// Input message for creating a new message in the store
///
/// This is the input structure for adding messages, without the ID and timestamp
/// which are generated by the store.
#[derive(Debug, Clone)]
pub struct InputMessage {
    /// Message role (user, assistant, tool_result, system)
    pub role: MessageRole,
    /// Message content as array of content parts
    pub content: Vec<ContentPart>,
    /// Runtime controls (model, reasoning, etc.)
    pub controls: Option<Controls>,
    /// Message-level metadata
    pub metadata: Option<std::collections::HashMap<String, serde_json::Value>>,
    /// Tags for filtering/categorization
    pub tags: Vec<String>,
}

impl InputMessage {
    /// Create a new user input message with text content
    pub fn user(content: impl Into<String>) -> Self {
        Self {
            role: MessageRole::User,
            content: vec![ContentPart::text(content)],
            controls: None,
            metadata: None,
            tags: vec![],
        }
    }

    /// Create from a Message (useful for storing existing messages)
    pub fn from_message(msg: &Message) -> Self {
        Self {
            role: msg.role.clone(),
            content: msg.content.clone(),
            controls: msg.controls.clone(),
            metadata: msg.metadata.clone(),
            tags: vec![],
        }
    }
}

/// Trait for storing and retrieving conversation messages
///
/// Implementations can:
/// - Store messages in a database
/// - Keep messages in memory for testing
/// - Communicate via gRPC to a control plane
#[async_trait]
pub trait MessageStore: Send + Sync {
    /// Add a new message to the store and return the stored message with generated ID
    ///
    /// This is the primary method for creating messages. The store generates
    /// the message ID and timestamp.
    async fn add(&self, session_id: Uuid, input: InputMessage) -> Result<Message>;

    /// Get a specific message by ID
    async fn get(&self, session_id: Uuid, message_id: Uuid) -> Result<Option<Message>>;

    /// Store a message (legacy method, uses add internally)
    ///
    /// Note: This method is kept for backward compatibility. Prefer using `add()` for new code.
    async fn store(&self, session_id: Uuid, message: Message) -> Result<()> {
        self.add(session_id, InputMessage::from_message(&message))
            .await?;
        Ok(())
    }

    /// Store multiple messages
    async fn store_batch(&self, session_id: Uuid, messages: Vec<Message>) -> Result<()> {
        for message in messages {
            self.store(session_id, message).await?;
        }
        Ok(())
    }

    /// Load all messages for a session
    async fn load(&self, session_id: Uuid) -> Result<Vec<Message>>;

    /// Load messages with pagination
    async fn load_page(
        &self,
        session_id: Uuid,
        offset: usize,
        limit: usize,
    ) -> Result<Vec<Message>> {
        let all = self.load(session_id).await?;
        Ok(all.into_iter().skip(offset).take(limit).collect())
    }

    /// Count messages in a session
    async fn count(&self, session_id: Uuid) -> Result<usize> {
        Ok(self.load(session_id).await?.len())
    }
}

// ============================================================================
// AgentStore - For retrieving agent configurations
// ============================================================================

/// Trait for retrieving agent configurations
///
/// Implementations can:
/// - Load agents from a database
/// - Keep agents in memory for testing
/// - Load agents via gRPC from control plane
#[async_trait]
pub trait AgentStore: Send + Sync {
    /// Get an agent by ID
    async fn get_agent(&self, agent_id: Uuid) -> Result<Option<Agent>>;
}

// ============================================================================
// SessionStore - For retrieving session information
// ============================================================================

/// Trait for retrieving session configurations
///
/// Implementations can:
/// - Load sessions from a database
/// - Keep sessions in memory for testing
/// - Load sessions via gRPC from control plane
#[async_trait]
pub trait SessionStore: Send + Sync {
    /// Get a session by ID
    async fn get_session(&self, session_id: Uuid) -> Result<Option<Session>>;
}

// ============================================================================
// LlmProviderStore - For retrieving LLM provider configurations
// ============================================================================

/// Model information with provider details needed for LLM calls
#[derive(Debug, Clone)]
pub struct ModelWithProvider {
    /// The model ID string to pass to the LLM API (e.g., "gpt-4o", "claude-3-opus")
    pub model: String,
    /// Provider type for factory selection
    pub provider_type: LlmProviderType,
    /// Decrypted API key (if configured)
    pub api_key: Option<String>,
    /// Optional base URL override
    pub base_url: Option<String>,
}

/// Trait for retrieving LLM provider and model configurations
///
/// This trait abstracts the database lookup and API key decryption needed
/// to create LLM providers at runtime.
///
/// Implementations can:
/// - Load from a database with encrypted API keys
/// - Use in-memory configurations for testing
/// - Load via gRPC from control plane (API keys decrypted server-side)
#[async_trait]
pub trait LlmProviderStore: Send + Sync {
    /// Get model with provider info by model UUID
    ///
    /// Returns the model string ID, provider type, decrypted API key, and base URL
    /// needed to create an LLM provider via the factory.
    async fn get_model_with_provider(&self, model_id: Uuid) -> Result<Option<ModelWithProvider>>;

    /// Get the default model with provider info
    ///
    /// Returns the system default model when an agent has no default_model_id set.
    async fn get_default_model(&self) -> Result<Option<ModelWithProvider>>;
}

// ============================================================================
// ToolExecutor - For executing tool calls
// ============================================================================

/// Trait for executing tool calls
///
/// Implementations handle the actual tool execution:
/// - Built-in function execution
/// - Capability-provided tools
/// - Mock execution for testing
#[async_trait]
pub trait ToolExecutor: Send + Sync {
    /// Execute a single tool call (without context)
    ///
    /// This is the legacy method that doesn't provide context to tools.
    /// Use `execute_with_context` when context is available.
    async fn execute(&self, tool_call: &ToolCall, tool_def: &ToolDefinition) -> Result<ToolResult>;

    /// Execute a single tool call with context
    ///
    /// This method provides runtime context to tools that need it (like filesystem tools).
    /// The default implementation delegates to `execute()`.
    async fn execute_with_context(
        &self,
        tool_call: &ToolCall,
        tool_def: &ToolDefinition,
        _context: &ToolContext,
    ) -> Result<ToolResult> {
        // Default: delegate to execute(), ignoring context
        self.execute(tool_call, tool_def).await
    }

    /// Execute multiple tool calls (default: sequential)
    async fn execute_batch(
        &self,
        tool_calls: &[ToolCall],
        tool_defs: &[ToolDefinition],
    ) -> Result<Vec<ToolResult>> {
        let mut results = Vec::with_capacity(tool_calls.len());

        // Build a map of tool names to definitions
        let tool_map: std::collections::HashMap<&str, &ToolDefinition> = tool_defs
            .iter()
            .map(|def| {
                let name = match def {
                    ToolDefinition::Builtin(b) => b.name.as_str(),
                };
                (name, def)
            })
            .collect();

        for tool_call in tool_calls {
            let tool_def = tool_map.get(tool_call.name.as_str()).ok_or_else(|| {
                crate::error::AgentLoopError::tool(format!(
                    "Tool definition not found: {}",
                    tool_call.name
                ))
            })?;

            results.push(self.execute(tool_call, tool_def).await?);
        }

        Ok(results)
    }

    /// Execute multiple tool calls in parallel
    async fn execute_parallel(
        &self,
        tool_calls: &[ToolCall],
        tool_defs: &[ToolDefinition],
    ) -> Result<Vec<ToolResult>>
    where
        Self: Sized,
    {
        use futures::future::join_all;

        // Build a map of tool names to definitions
        let tool_map: std::collections::HashMap<&str, &ToolDefinition> = tool_defs
            .iter()
            .map(|def| {
                let name = match def {
                    ToolDefinition::Builtin(b) => b.name.as_str(),
                };
                (name, def)
            })
            .collect();

        let futures: Vec<_> = tool_calls
            .iter()
            .map(|tool_call| async {
                let tool_def = tool_map.get(tool_call.name.as_str()).ok_or_else(|| {
                    crate::error::AgentLoopError::tool(format!(
                        "Tool definition not found: {}",
                        tool_call.name
                    ))
                })?;
                self.execute(tool_call, tool_def).await
            })
            .collect();

        let results = join_all(futures).await;
        results.into_iter().collect()
    }
}

// ============================================================================
// SessionFileStore - For session filesystem operations
// ============================================================================

/// Trait for session filesystem operations
///
/// This trait abstracts file operations for tools that need to interact with
/// the session's virtual filesystem. Implementations can:
/// - Store files in a database (production)
/// - Use an in-memory filesystem for testing
/// - Communicate via gRPC to control plane
#[async_trait]
pub trait SessionFileStore: Send + Sync {
    /// Read a file by path
    async fn read_file(&self, session_id: Uuid, path: &str) -> Result<Option<SessionFile>>;

    /// Write/create a file
    async fn write_file(
        &self,
        session_id: Uuid,
        path: &str,
        content: &str,
        encoding: &str,
    ) -> Result<SessionFile>;

    /// Delete a file or directory
    async fn delete_file(&self, session_id: Uuid, path: &str, recursive: bool) -> Result<bool>;

    /// List files in a directory
    async fn list_directory(&self, session_id: Uuid, path: &str) -> Result<Vec<FileInfo>>;

    /// Get file metadata
    async fn stat_file(&self, session_id: Uuid, path: &str) -> Result<Option<FileStat>>;

    /// Search files by pattern (grep)
    async fn grep_files(
        &self,
        session_id: Uuid,
        pattern: &str,
        path_pattern: Option<&str>,
    ) -> Result<Vec<GrepMatch>>;

    /// Create a directory
    async fn create_directory(&self, session_id: Uuid, path: &str) -> Result<FileInfo>;
}

// ============================================================================
// ToolContext - Runtime context for tool execution
// ============================================================================

/// Runtime context provided to tools during execution.
///
/// This context contains:
/// - Session ID for scoping operations
/// - Optional stores for tools that need external access
///
/// Tools that need context-aware execution (like filesystem tools) can use
/// the `execute_with_context` method on the Tool trait.
#[derive(Clone)]
pub struct ToolContext {
    /// The session ID for the current execution
    pub session_id: Uuid,

    /// Optional file store for filesystem operations
    pub file_store: Option<Arc<dyn SessionFileStore>>,
}

impl ToolContext {
    /// Create a new tool context with just a session ID
    pub fn new(session_id: Uuid) -> Self {
        Self {
            session_id,
            file_store: None,
        }
    }

    /// Create a context with a file store
    pub fn with_file_store(session_id: Uuid, file_store: Arc<dyn SessionFileStore>) -> Self {
        Self {
            session_id,
            file_store: Some(file_store),
        }
    }
}

impl std::fmt::Debug for ToolContext {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("ToolContext")
            .field("session_id", &self.session_id)
            .field("file_store", &self.file_store.is_some())
            .finish()
    }
}

// ============================================================================
// EventEmitter - For emitting events
// ============================================================================

/// Trait for emitting events following the standard event protocol
///
/// Implementations can:
/// - Store events in a database
/// - Keep events in memory for testing
/// - Stream events via gRPC to control plane
/// - Log events for debugging
///
/// Events follow a consistent schema: id, type, ts, context, data.
/// See specs/events.md for the full event protocol specification.
#[async_trait]
pub trait EventEmitter: Send + Sync {
    /// Emit an event
    ///
    /// Returns the assigned sequence number within the session.
    async fn emit(&self, event: Event) -> Result<i32>;
}

/// No-op event emitter for when event emission is not needed
///
/// This is useful for testing or when event observability is disabled.
#[derive(Debug, Clone, Default)]
pub struct NoopEventEmitter;

#[async_trait]
impl EventEmitter for NoopEventEmitter {
    async fn emit(&self, _event: Event) -> Result<i32> {
        Ok(0)
    }
}
