{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Everruns Agent API Example\n\nThis notebook demonstrates how to use the Everruns API to:\n1. Create an agent with a system prompt\n2. Create a session (conversation)\n3. Send a message to trigger the agentic loop\n4. Read events until the assistant response appears\n5. Continue the conversation\n\n## Prerequisites\n\n- Everruns API server running at `http://localhost:9000`\n- Python packages: `requests`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n!pip install requests"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import requests\nimport json\nimport time\n\n# Configuration\nBASE_URL = \"http://localhost:9000\"\nAPI_V1 = f\"{BASE_URL}/v1\"\n\n# Track the last event offset for efficient continuation\nlast_offset = 0\n\ndef print_json(data):\n    \"\"\"Pretty print JSON data.\"\"\"\n    print(json.dumps(data, indent=2, default=str))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Health Check\n",
    "\n",
    "Verify the API server is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"{BASE_URL}/health\")\n",
    "response.raise_for_status()\n",
    "print(\"API Status:\", response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an Agent\n",
    "\n",
    "An agent is a configuration for an agentic loop with a system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_data = {\n",
    "    \"name\": \"Python Example Agent\",\n",
    "    \"description\": \"A helpful assistant created via the Python API\",\n",
    "    \"system_prompt\": \"You are a helpful assistant. Be concise and friendly.\",\n",
    "    \"tags\": [\"example\", \"python\"]\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{API_V1}/agents\", json=agent_data)\n",
    "response.raise_for_status()\n",
    "agent = response.json()\n",
    "\n",
    "agent_id = agent[\"id\"]\n",
    "print(f\"Created agent: {agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a Session\n",
    "\n",
    "A session is an instance of conversation with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data = {\n",
    "    \"title\": \"Python API Test Session\"\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{API_V1}/agents/{agent_id}/sessions\", json=session_data)\n",
    "response.raise_for_status()\n",
    "session = response.json()\n",
    "\n",
    "session_id = session[\"id\"]\n",
    "print(f\"Created session: {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Send a Message\n",
    "\n",
    "Sending a user message triggers the agentic loop workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data = {\n",
    "    \"message\": {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What is 2 + 2? Please explain briefly.\"}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_V1}/agents/{agent_id}/sessions/{session_id}/messages\",\n",
    "    json=message_data\n",
    ")\n",
    "response.raise_for_status()\n",
    "print(f\"Sent message: {response.json()['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Read Events\n\nPoll the events endpoint to get the assistant's response. Events include messages (`message.assistant`, `message.tool_call`, `message.tool_result`) and loop lifecycle events."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def read_until_output(agent_id: str, session_id: str, offset: int = 0, timeout: int = 60):\n    \"\"\"Poll events until an assistant message appears.\n    \n    Uses offset-based pagination for efficient event fetching:\n    - Pass the last known offset to resume from that point\n    - Returns (response_text, next_offset) for continuation\n    \n    This follows the durable streams pattern where clients track their\n    position and can resume from any offset after reconnection.\n    \"\"\"\n    url = f\"{API_V1}/agents/{agent_id}/sessions/{session_id}/events\"\n    current_offset = offset\n    start_time = time.time()\n    \n    while time.time() - start_time < timeout:\n        # Use offset parameter to only fetch new events\n        response = requests.get(url, params={\"offset\": current_offset, \"limit\": 100})\n        response.raise_for_status()\n        result = response.json()\n        \n        events = result.get(\"data\", [])\n        next_offset = result.get(\"next_offset\")\n        has_more = result.get(\"has_more\", False)\n        \n        for event in events:\n            event_type = event[\"event_type\"]\n            data = event[\"data\"]\n            seq = event[\"sequence\"]\n            \n            # Print event details\n            if event_type == \"message.assistant\":\n                content = data.get(\"content\", [])\n                text_parts = [p[\"text\"] for p in content if p.get(\"type\") == \"text\"]\n                text = \"\\n\".join(text_parts)\n                print(f\"[{event_type}] {text[:100]}{'...' if len(text) > 100 else ''}\")\n                # Return the response and the offset to continue from\n                return text, next_offset if next_offset else seq\n            elif event_type == \"message.tool_call\":\n                content = data.get(\"content\", [])\n                for part in content:\n                    if part.get(\"type\") == \"tool_call\":\n                        print(f\"[{event_type}] {part.get('name')}({part.get('arguments')})\")\n            elif event_type == \"message.tool_result\":\n                content = data.get(\"content\", [])\n                for part in content:\n                    if part.get(\"type\") == \"tool_result\":\n                        result_data = part.get(\"result\", \"\")\n                        print(f\"[{event_type}] {str(result_data)[:80]}...\")\n            elif event_type == \"checkpoint\":\n                # Checkpoint events mark safe resumption points\n                status = data.get(\"status\", \"\")\n                print(f\"[checkpoint] status={status}, last_seq={data.get('last_sequence')}\")\n            elif event_type == \"LoopCompleted\":\n                print(f\"[{event_type}] iterations={data.get('total_iterations')}\")\n            elif event_type in (\"LoopStarted\", \"IterationStarted\", \"LlmCallStarted\", \"LlmCallCompleted\"):\n                print(f\"[{event_type}]\")\n            elif event_type == \"LoopError\":\n                print(f\"[{event_type}] {data.get('error')}\")\n                return None, next_offset if next_offset else current_offset\n        \n        # Update offset for next poll\n        if next_offset:\n            current_offset = next_offset\n        \n        time.sleep(0.5)\n    \n    return None, current_offset\n\n# Read events until we get the assistant's response\nprint(\"Waiting for assistant response...\\n\")\nassistant_response, last_offset = read_until_output(agent_id, session_id, offset=0)\n\nif assistant_response:\n    print(f\"\\n--- ASSISTANT ---\")\n    print(assistant_response)\n    print(f\"\\n(Saved offset: {last_offset} for continuation)\")\nelse:\n    print(\"No response received\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Continue the Conversation\n",
    "\n",
    "Send another message and read the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Send follow-up message\nmessage_data = {\n    \"message\": {\n        \"content\": [\n            {\"type\": \"text\", \"text\": \"What about 3 + 3?\"}\n        ]\n    }\n}\n\nresponse = requests.post(\n    f\"{API_V1}/agents/{agent_id}/sessions/{session_id}/messages\",\n    json=message_data\n)\nresponse.raise_for_status()\nprint(f\"Sent follow-up message (resuming from offset {last_offset})\\n\")\n\n# Read response using the saved offset - only fetches NEW events\nassistant_response, last_offset = read_until_output(agent_id, session_id, offset=last_offset)\n\nif assistant_response:\n    print(f\"\\n--- ASSISTANT ---\")\n    print(assistant_response)\n    print(f\"\\n(Saved offset: {last_offset} for next continuation)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup\n",
    "\n",
    "Delete the session and archive the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete session\n",
    "requests.delete(f\"{API_V1}/agents/{agent_id}/sessions/{session_id}\")\n",
    "print(f\"Deleted session: {session_id}\")\n",
    "\n",
    "# Archive agent\n",
    "requests.delete(f\"{API_V1}/agents/{agent_id}\")\n",
    "print(f\"Archived agent: {agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nCore API workflow:\n\n1. `POST /v1/agents` - Create agent\n2. `POST /v1/agents/{id}/sessions` - Create session\n3. `POST /v1/agents/{id}/sessions/{id}/messages` - Send user message (triggers agentic loop)\n4. `GET /v1/agents/{id}/sessions/{id}/events?offset=N&limit=M` - Poll events with offset-based pagination\n\n### Offset-Based Event Fetching (Durable Streams Pattern)\n\nThe events endpoint supports offset-based pagination for efficient event streaming:\n\n- `?offset=N` - Fetch events with sequence > N (resume from position)\n- `?limit=M` - Limit number of events per request (default: 100, max: 1000)\n- Response includes `next_offset` and `has_more` for continuation\n\n**Benefits:**\n- **Efficient**: Only fetch new events, not the entire history\n- **Resumable**: Save `next_offset` and resume after disconnection\n- **Cacheable**: Historical pages have `Cache-Control: immutable`\n\n### Event Types\n\nEvents contain all session activity including messages:\n\n- `message.user` - User message\n- `message.assistant` - Assistant response with content\n- `message.tool_call` - Tool invocation by assistant\n- `message.tool_result` - Result of tool execution\n- `checkpoint` - Safe resumption point (status + last_sequence)\n- `LoopStarted`, `LoopCompleted` - Agentic loop lifecycle\n- `LlmCallStarted`, `LlmCallCompleted` - LLM call lifecycle\n\nAPI docs: http://localhost:9000/swagger-ui/"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}